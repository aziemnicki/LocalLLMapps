import streamlit as st
import ollama
from PIL import Image
import base64
from io import BytesIO

# Konfiguracja strony
st.set_page_config(
    page_title="Gemma-3 AI Assistant",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Funkcja do konwersji obrazu na base64
def image_to_base64(image):
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

# Funkcja do wysy≈Çania zapyta≈Ñ do modelu
def query_model(messages, model_name="gemma3"):
    try:
        response = ollama.chat(model=model_name, messages=messages)
        return response["message"]["content"]
    except Exception as e:
        return f"WystƒÖpi≈Ç b≈ÇƒÖd: {str(e)}"

# Inicjalizacja stanu sesji
if "text_messages" not in st.session_state:
    st.session_state.text_messages = []
    
if "image_messages" not in st.session_state:
    st.session_state.image_messages = []

# Stylizacja
st.markdown("""
<style>
    .main {
        background-color: #f5f5f5;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        flex-direction: column;
    }
    .user-message {
        background-color: #e1f5fe;
        border-left: 5px solid #039be5;
    }
    .bot-message {
        background-color: #f0f4c3;
        border-left: 5px solid #afb42b;
    }
    .message-content {
        display: flex;
        flex-direction: column;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: #f0f2f6;
        border-radius: 4px 4px 0px 0px;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #e1f5fe;
    }
    
    /* Styl dla kontenera wiadomo≈õci tekstowych */
    .text-chat-container {
        display: flex;
        flex-direction: column;
        height: 70vh;
        overflow-y: auto;
        padding: 10px;
        margin-bottom: 20px;
    }
    
    /* Styl dla kontenera inputu tekstowego na dole */
    .text-input-container {
        position: fixed;
        bottom: 20px;
        width: 100%;
        padding: 10px;
        background-color: #f5f5f5;
        z-index: 1000;
    }
    
    /* Centrowanie wiadomo≈õci */
    .centered-messages {
        max-width: 800px;
        margin: 0 auto;
    }
</style>
""", unsafe_allow_html=True)

# Tytu≈Ç aplikacji
st.title("ü§ñ Gemma-3 AI Assistant")
st.markdown("Asystent AI oparty na modelu Gemma-3 z Ollama")

# Sidebar z informacjami
with st.sidebar:
    st.header("Informacje")
    st.info("Ta aplikacja wykorzystuje model Gemma-3 uruchomiony lokalnie przez Ollama.")
    
    st.header("Ustawienia")
    model_choice = st.selectbox(
        "Wybierz model",
        ["gemma3:1b", "gemma3:4b", "gemma3:12b", "gemma3:27b"],
        index=3
    )
    
    st.header("O aplikacji")
    st.markdown("""
    ### Funkcje:
    - Chat tekstowy
    - Analiza obraz√≥w
    - Lokalne przetwarzanie (prywatno≈õƒá)
    
    ### Wymagania:
    - Zainstalowany Ollama
    - Pobrany model Gemma-3
    """)
    
    if st.button("Wyczy≈õƒá historiƒô"):
        st.session_state.text_messages = []
        st.session_state.image_messages = []
        st.rerun()

# Zak≈Çadki
tab1, tab2 = st.tabs(["üí¨ Chat tekstowy", "üñºÔ∏è Chat z obrazami"])

# Zak≈Çadka 1: Chat tekstowy - NOWY UK≈ÅAD
with tab1:
    # Kontener na historiƒô wiadomo≈õci
    chat_container = st.container()
    
    # Kontener na input
    input_container = st.container()
    
    # Wy≈õwietl historiƒô wiadomo≈õci w kontenerze
    with chat_container:
        st.markdown('<div class="centered-messages">', unsafe_allow_html=True)
        for message in st.session_state.text_messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Pole wprowadzania tekstu w kontenerze na dole
    with input_container:
        user_input = st.chat_input("Wpisz wiadomo≈õƒá...")
    
    if user_input:
        # Dodaj wiadomo≈õƒá u≈ºytkownika do historii
        st.session_state.text_messages.append({"role": "user", "content": user_input})
        
        # Przygotuj wiadomo≈õci dla modelu
        messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.text_messages]
        
        # Uzyskaj odpowied≈∫ od modelu
        response = query_model(messages)
        
        # Dodaj odpowied≈∫ modelu do historii
        st.session_state.text_messages.append({"role": "assistant", "content": response})
        
        # Od≈õwie≈º stronƒô, aby pokazaƒá nowe wiadomo≈õci
        st.rerun()

# Zak≈Çadka 2: Chat z obrazami - POPRZEDNI UK≈ÅAD
with tab2:
    # Wy≈õwietl historiƒô wiadomo≈õci
    for message in st.session_state.image_messages:
        with st.chat_message(message["role"]):
            if "images" in message and message["images"] is not None:
                st.image(message["images"][0], caption="Przes≈Çany obraz", width=300)
            st.write(message["content"])
    
    # Pole do przesy≈Çania obrazu
    uploaded_file = st.file_uploader("Choose an image...", type=['png', 'jpg', 'jpeg'])
    
    # Pole wprowadzania tekstu
    image_prompt = st.text_input("Opisz obraz lub zadaj pytanie...")
    
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="Przes≈Çany obraz", width=300)
    
    # Przycisk do wys≈Çania
    if st.button("Wy≈õlij zapytanie z obrazem") and image_prompt and uploaded_file is not None:
        # Dodaj wiadomo≈õƒá u≈ºytkownika do historii
        st.session_state.image_messages.append({
            "role": "user", 
            "content": str(image_prompt),
            "images": [uploaded_file.getvalue()]
        })
        
        # Wy≈õwietl wiadomo≈õƒá u≈ºytkownika
        with st.chat_message("user"):
            st.image(uploaded_file, caption="Przes≈Çany obraz", width=300)
            st.write(image_prompt)
            
        # Przygotuj wiadomo≈õci dla modelu multimodalnego
        messages = [{
            "role": "user",
            "content": str(image_prompt),
            "images": [uploaded_file.getvalue()]
        }]
        
        # Poka≈º, ≈ºe model my≈õli
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.write("Analizujƒô obraz...")
            
            # Uzyskaj odpowied≈∫ od modelu
            response = query_model(messages)
            
            # Wy≈õwietl odpowied≈∫
            message_placeholder.write(response)
        
        # Dodaj odpowied≈∫ modelu do historii
        st.session_state.image_messages.append({
            "role": "assistant", 
            "content": response,
            "images": None
        })
